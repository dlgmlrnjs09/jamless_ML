from fastapi import FastAPI, HTTPException, Request
from pydantic import BaseModel
from typing import List, Dict, Any
import pandas as pd
import numpy as np
import traceback
from datetime import date, datetime

from models.prophet_model import train_prophet_model, predict_with_prophet
from models.xgboost_model import train_xgboost_model, predict_residuals
from utils.data_utils import prepare_data, density_to_crowd_level

app = FastAPI(title="Crowd Forecast API")

# ì˜ˆì™¸ë¥¼ ì½˜ì†”ì— ì¶œë ¥í•˜ëŠ” ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
@app.middleware("http")
async def log_exceptions_middleware(request: Request, call_next):
    try:
        return await call_next(request)
    except Exception as e:
        print("â— ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ:")
        traceback.print_exc()  # ì½˜ì†”ì— ì „ì²´ ì—ëŸ¬ ìŠ¤íƒ ì¶œë ¥
        raise e

class ForecastRequest(BaseModel):
    historicalData: List[Dict[str, Any]]
    futureDates: List[Dict[str, Any]]

class ForecastResponse(BaseModel):
    predictions: List[Dict[str, Any]]
    metrics: Dict[str, Any]

@app.get("/")
def read_root():
    return {"message": "Crowd Forecast API is running"}

@app.post("/api/forecast/prophet-xgboost", response_model=ForecastResponse)
async def forecast_with_prophet_xgboost(request: ForecastRequest):
    try:
        print("ğŸ“¥ forecast_with_prophet_xgboost í˜¸ì¶œë¨")

        # 1. ë°ì´í„° ì¤€ë¹„
        historical_df, future_df, feature_cols = prepare_data(
            request.historicalData, request.futureDates
        )
        print("âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")

        # 2. Prophet ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
        prophet_model = train_prophet_model(historical_df)
        prophet_historical_pred, prophet_future_pred = predict_with_prophet(
            prophet_model, historical_df[['ds']], future_df[['ds']]
        )
        print("âœ… Prophet ì˜ˆì¸¡ ì™„ë£Œ")

        # 3. ì”ì°¨ ê³„ì‚°
        historical_df['prophet_pred'] = prophet_historical_pred['yhat'].values
        historical_df['residuals'] = historical_df['y'] - historical_df['prophet_pred']

        # 4. XGBoost ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
        xgb_model, metrics, feature_importance = train_xgboost_model(
            historical_df, feature_cols
        )
        print("âœ… XGBoost í•™ìŠµ ë° ì˜ˆì¸¡ ì™„ë£Œ")

        future_df['prophet_pred'] = prophet_future_pred['yhat'].values
        future_df['residual_pred'] = predict_residuals(xgb_model, future_df, feature_cols)

        # 5. ìµœì¢… ì˜ˆì¸¡ ê³„ì‚°
        future_df['final_pred'] = future_df['prophet_pred'] + future_df['residual_pred']
        future_df['final_pred'] = future_df['final_pred'].clip(lower=0)

        # 6. í˜¼ì¡ë„ ë ˆë²¨ ê³„ì‚°
        future_df['crowd_level'] = future_df['final_pred'].apply(density_to_crowd_level)

        # 7. ì‹ ë¢° êµ¬ê°„ ê³„ì‚°
        future_df['lower_bound'] = prophet_future_pred['yhat_lower'] + future_df['residual_pred']
        future_df['upper_bound'] = prophet_future_pred['yhat_upper'] + future_df['residual_pred']
        future_df['lower_bound'] = future_df['lower_bound'].clip(lower=0)

        # 8. ì‘ë‹µ ì¤€ë¹„
        predictions = []
        prediction_comments = {}  # ì˜ˆì¸¡ ê²°ê³¼ì— ëŒ€í•œ ì„¤ëª… ì €ì¥

        # Prophet ë° XGBoost ëª¨ë¸ì˜ ì£¼ìš” ìš”ì¸ íŒŒì•…
        prophet_components = prophet_future_pred[['ds', 'trend', 'yearly', 'weekly', 'multiplicative_terms']]

        # XGBoost ëª¨ë¸ì˜ íŠ¹ì„± ì¤‘ìš”ë„
        feature_importance_dict = dict(zip(feature_cols, xgb_model.feature_importances_))
        top_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)[:3]

        for _, row in future_df.iterrows():
            # ë‚ ì§œì—ì„œ ì‹œê°„ ë¶€ë¶„ ì œê±°
            date_only = str(row['ds']).split(' ')[0] if ' ' in str(row['ds']) else str(row['ds'])
            date_obj = pd.to_datetime(date_only).date()

            # í•´ë‹¹ ë‚ ì§œì˜ Prophet ì»´í¬ë„ŒíŠ¸ ì°¾ê¸°
            prophet_comp = prophet_components[prophet_components['ds'].dt.date == date_obj]

            # ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±
            prediction = {
                'date': date_only,
                'predictedDensity': float(row['final_pred']),
                'crowdLevel': int(row['crowd_level']),
                'lowerBound': float(row['lower_bound']),
                'upperBound': float(row['upper_bound'])
            }

            # ì¶”ê°€ íŠ¹ì„± í¬í•¨
            for col in ['isWeekend', 'isHoliday', 'isSchoolVacation', 'temperature']:
                if col in row:
                    val = row[col]
                    if isinstance(val, (np.integer, np.floating, np.bool_)):
                        val = val.item()
                    prediction[col] = val

            # ì˜ˆì¸¡ ì„¤ëª… ìƒì„±
            comment = generate_prediction_comment(
                date_obj,
                row,
                prophet_comp,
                historical_df,
                top_features,
                feature_cols
            )

            prediction_comments[date_only] = comment
            predictions.append(prediction)

        # 9. ì§€í‘œ ë° íŠ¹ì„± ì¤‘ìš”ë„
        # NumPy ë°ì´í„° íƒ€ì… ë³€í™˜
        response_metrics = {
            'mae': float(metrics['mae']),  # ëª…ì‹œì ìœ¼ë¡œ floatë¡œ ë³€í™˜
            'rmse': float(metrics['rmse']), # ëª…ì‹œì ìœ¼ë¡œ floatë¡œ ë³€í™˜
        }

        # feature_importance ì²˜ë¦¬: NumPy ë°ì´í„° íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        converted_feature_importance = {}
        for k, v in feature_importance_dict.items():
            if isinstance(v, (np.integer, np.floating, np.bool_)):
                converted_feature_importance[k] = v.item()
            else:
                converted_feature_importance[k] = v

        response_metrics['featureImportance'] = converted_feature_importance
        response_metrics['predictionComments'] = prediction_comments

        print("âœ… ì˜ˆì¸¡ ì‘ë‹µ ë°˜í™˜ ì™„ë£Œ")
        return ForecastResponse(predictions=predictions, metrics=response_metrics)

    except Exception as e:
        print("âŒ forecast_with_prophet_xgboost ë‚´ë¶€ ì˜ˆì™¸:")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


def generate_prediction_comment(date, row, prophet_comp, historical_df, top_features, feature_cols):
    """ì˜ˆì¸¡ ê²°ê³¼ì— ëŒ€í•œ ì„¤ëª… ìƒì„±"""
    comment = f"{date.strftime('%Yë…„ %mì›” %dì¼')}ì˜ í˜¼ì¡ë„ ì˜ˆì¸¡ ì„¤ëª…:\n"

    # 1. ìš”ì¼ ë° ì£¼ë§ ì—¬ë¶€
    weekdays = {0: 'ì›”ìš”ì¼', 1: 'í™”ìš”ì¼', 2: 'ìˆ˜ìš”ì¼', 3: 'ëª©ìš”ì¼', 4: 'ê¸ˆìš”ì¼', 5: 'í† ìš”ì¼', 6: 'ì¼ìš”ì¼'}
    day_of_week = date.weekday()
    day_name = weekdays[day_of_week]
    is_weekend = int(row.get('isWeekend', 0)) == 1
    day_type = "ì£¼ë§" if is_weekend else "í‰ì¼"
    comment += f"- í•´ë‹¹ ì¼ìëŠ” {day_name}({day_type})ì…ë‹ˆë‹¤.\n"

    # 2. íŠ¹ë³„ ì¼ì (ê³µíœ´ì¼, ë°©í•™ ë“±)
    is_holiday = int(row.get('isHoliday', 0)) == 1
    is_vacation = int(row.get('isSchoolVacation', 0)) == 1

    if is_holiday:
        holiday_name = row.get('holidayName', 'ê³µíœ´ì¼')
        comment += f"- ì´ ë‚ ì€ {holiday_name}ì…ë‹ˆë‹¤.\n"

    if is_vacation:
        vacation_type = row.get('vacationType', 'ë°©í•™')
        comment += f"- ì´ ë‚ ì€ {vacation_type} ê¸°ê°„ì…ë‹ˆë‹¤.\n"

    # 3. ë‚ ì”¨ ì •ë³´
    if 'temperature' in row and row['temperature'] is not None:
        temp = float(row['temperature'])
        comment += f"- ì˜ˆìƒ ê¸°ì˜¨ì€ {temp:.1f}Â°Cì…ë‹ˆë‹¤.\n"

    if 'isRainy' in row and int(row.get('isRainy', 0)) == 1:
        comment += f"- ì´ ë‚ ì€ ë¹„ ì˜ˆë³´ê°€ ìˆì–´ ë°©ë¬¸ê° ìˆ˜ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"

    # 4. ê³¼ê±° ìœ ì‚¬ ì¼ì ì°¾ê¸°
    similar_dates = find_similar_dates(date, historical_df)
    if similar_dates:
        similar_date, similarity, crowd_level = similar_dates[0]
        crowd_level_desc = get_crowd_level_description(crowd_level)
        comment += f"- ê³¼ê±° ìœ ì‚¬ ì¼ìì¸ {similar_date.strftime('%Yë…„ %mì›” %dì¼')}ì˜ í˜¼ì¡ë„ëŠ” {crowd_level}({crowd_level_desc})ì´ì—ˆìŠµë‹ˆë‹¤.\n"

    # 5. ì£¼ìš” ì˜í–¥ ìš”ì¸
    comment += "- ì˜ˆì¸¡ì— ê°€ì¥ í° ì˜í–¥ì„ ì¤€ ìš”ì¸:\n"

    # Prophet íŠ¸ë Œë“œ ë° ê³„ì ˆì„± íš¨ê³¼
    if not prophet_comp.empty:
        trend_effect = prophet_comp['trend'].values[0]
        weekly_effect = prophet_comp['weekly'].values[0] if 'weekly' in prophet_comp else 0
        yearly_effect = prophet_comp['yearly'].values[0] if 'yearly' in prophet_comp else 0

        comment += f"  * ì¥ê¸° íŠ¸ë Œë“œ: {'ì¦ê°€' if trend_effect > 0 else 'ê°ì†Œ'} ì¶”ì„¸\n"
        comment += f"  * ì£¼ê°„ íŒ¨í„´: í•´ë‹¹ ìš”ì¼ì€ í‰ê·  ëŒ€ë¹„ {'+' if weekly_effect > 0 else ''}{weekly_effect:.2f} ì˜í–¥\n"
        comment += f"  * ì—°ê°„ íŒ¨í„´: í•´ë‹¹ ì›”/ì¼ì€ í‰ê·  ëŒ€ë¹„ {'+' if yearly_effect > 0 else ''}{yearly_effect:.2f} ì˜í–¥\n"

    # XGBoost íŠ¹ì„± ì¤‘ìš”ë„
    for feature, importance in top_features:
        if feature in row:
            feature_value = row[feature]
            if isinstance(feature_value, (np.integer, np.floating, np.bool_)):
                feature_value = feature_value.item()

            # íŠ¹ì„± ì´ë¦„ ê°€ë…ì„± í–¥ìƒ
            feature_name = {
                'isWeekend': 'ì£¼ë§ ì—¬ë¶€',
                'isHoliday': 'ê³µíœ´ì¼ ì—¬ë¶€',
                'isSchoolVacation': 'ë°©í•™ ì—¬ë¶€',
                'temperature': 'ê¸°ì˜¨',
                'dayOfWeek': 'ìš”ì¼',
                'month': 'ì›”',
                'isRainy': 'ê°•ìˆ˜ ì—¬ë¶€'
            }.get(feature, feature)

            comment += f"  * {feature_name}: {feature_value} (ì¤‘ìš”ë„: {importance:.4f})\n"

    # 6. ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼
    density = float(row['final_pred'])
    crowd_level = int(row['crowd_level'])
    crowd_level_desc = get_crowd_level_description(crowd_level)

    comment += f"\nìµœì¢… ì˜ˆì¸¡: ë‹¨ìœ„ ë©´ì ë‹¹ ë°©ë¬¸ì ìˆ˜ {density:.6f}ëª…/ã¡ë¡œ í˜¼ì¡ë„ {crowd_level}ë‹¨ê³„({crowd_level_desc})ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤."

    return comment


def find_similar_dates(target_date, historical_df):
    """ê³¼ê±° ë°ì´í„°ì—ì„œ ìœ ì‚¬í•œ ë‚ ì§œ ì°¾ê¸°"""
    similar_dates = []

    if 'ds' not in historical_df.columns or historical_df.empty:
        return similar_dates

    for _, row in historical_df.iterrows():
        hist_date = pd.to_datetime(row['ds']).date()

        # ê°™ì€ ì›”/ì¼ì¸ ê²½ìš°
        if hist_date.month == target_date.month and hist_date.day == target_date.day:
            # ê°™ì€ ìš”ì¼ì¸ì§€ í™•ì¸
            if hist_date.weekday() == target_date.weekday():
                similarity = 1.0  # ë§¤ìš° ìœ ì‚¬ (ê°™ì€ ì›”/ì¼, ê°™ì€ ìš”ì¼)
            else:
                similarity = 0.8  # ë‹¤ì†Œ ìœ ì‚¬ (ê°™ì€ ì›”/ì¼, ë‹¤ë¥¸ ìš”ì¼)

            if 'crowd_level' in row:
                crowd_level = row['crowd_level']
            elif 'y' in row:
                # í˜¼ì¡ë„ ê³„ì‚°
                density = float(row['y'])
                crowd_level = density_to_crowd_level(density)
            else:
                crowd_level = None

            similar_dates.append((hist_date, similarity, crowd_level))

    # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    similar_dates.sort(key=lambda x: x[1], reverse=True)
    return similar_dates


def get_crowd_level_description(crowd_level):
    """í˜¼ì¡ë„ ë ˆë²¨ì— ëŒ€í•œ ì„¤ëª… ë°˜í™˜"""
    descriptions = {
        1: "ì—¬ìœ ",
        2: "ë³´í†µ",
        3: "í˜¼ì¡",
        4: "ë§¤ìš° í˜¼ì¡"
    }
    return descriptions.get(crowd_level, "ì•Œ ìˆ˜ ì—†ìŒ")


# ê¸°ì¡´ì˜ ì¶”ê°€ ì—”ë“œí¬ì¸íŠ¸: ë¡¯ë°ì›”ë“œ ì˜ˆì¸¡
@app.get("/api/forecast/lotte-world")
async def get_lotte_world_forecast(days: int = 30):
    try:
        return {"message": f"ë¡¯ë°ì›”ë“œ {days}ì¼ ì˜ˆì¸¡ APIëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
    except Exception as e:
        print("âŒ ë¡¯ë°ì›”ë“œ ì˜ˆì¸¡ API ì˜¤ë¥˜:", e)
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="debug")